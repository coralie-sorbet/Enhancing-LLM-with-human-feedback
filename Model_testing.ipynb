{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **End-to-End Reinforcement Learning with Human Feedback: Reward Modeling and PPO Testing on unseen texts**"
      ],
      "metadata": {
        "id": "CBOsrdVydIpz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATyYS9GWcvjq",
        "outputId": "3669d844-dfef-464a-88e2-59c58936cbeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Load Libraries**\n"
      ],
      "metadata": {
        "id": "-0Z02FCZc6Ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, pipeline\n",
        "# from trl import (\n",
        "#     AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer,\n",
        "#     RewardConfig, RewardTrainer, setup_chat_format, ModelConfig\n",
        "# )\n",
        "# from datasets import load_dataset"
      ],
      "metadata": {
        "id": "m9pw96M8c-LP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Models on Unseen Texts"
      ],
      "metadata": {
        "id": "VczRbRYUdEB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reward Model"
      ],
      "metadata": {
        "id": "VTD550KCdQ0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained reward model and tokenizer\n",
        "reward_model = AutoModelForSequenceClassification.from_pretrained(\"drive/MyDrive/M2 D3S/Math of DL/Project/reward_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"drive/MyDrive/M2 D3S/Math of DL/Project/reward_model\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "reward_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "\n",
        "# Test inputs and responses\n",
        "prompt = \"What is artificial intelligence?\"\n",
        "responses = [\n",
        "    \"AI is the simulation of human intelligence in machines.\",\n",
        "    \"AI is a field of engineering.\",\n",
        "]\n",
        "\n",
        "# Tokenize and score\n",
        "inputs = tokenizer([prompt] * len(responses), responses, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "# Check for and handle out-of-vocabulary tokens before passing to the model\n",
        "inputs['input_ids'] = inputs['input_ids'].clamp(0, tokenizer.vocab_size - 1)  # Clamp IDs within valid range\n",
        "\n",
        "scores = reward_model(**inputs).logits.squeeze()\n",
        "\n",
        "# Print scores\n",
        "for i, response in enumerate(responses):\n",
        "    print(f\"Response: {response}\\nScore: {scores[i].item()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVBczFrzdSzh",
        "outputId": "1406d27b-52f0-4846-89ff-09ceda4f82e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: AI is the simulation of human intelligence in machines.\n",
            "Score: 0.2086963653564453\n",
            "\n",
            "Response: AI is a field of engineering.\n",
            "Score: -2.861525774002075\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PPO model"
      ],
      "metadata": {
        "id": "Bg2aDmvRdUec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained policy model and tokenizer\n",
        "policy_model = AutoModelForCausalLM.from_pretrained(\"drive/MyDrive/M2 D3S/Math of DL/Project/ppo_optimized_policy\")\n",
        "generation_pipeline = pipeline(\"text-generation\",\n",
        "                               model=policy_model,\n",
        "                               tokenizer=tokenizer,\n",
        "                               device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "diverse_outputs = generation_pipeline(\"What is deep learning?\", max_length=50, num_return_sequences=5)\n",
        "# Calculate and print rewards for diverse_outputs\n",
        "for i, output in enumerate(diverse_outputs):\n",
        "    text = output['generated_text']\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    inputs['input_ids'] = inputs['input_ids'].clamp(0, tokenizer.vocab_size - 1)\n",
        "\n",
        "    score = reward_model(**inputs).logits[0].item()\n",
        "\n",
        "    print(f\"Response: {text}\\nScore: {score}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOYzv4xVdWfK",
        "outputId": "51f7411b-bd61-4650-95e7-d5e1842afe50"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: What is deep learning?\n",
            "\n",
            "It's an industry term. It refers to the ability to classify information among a collection of discrete neural networks. Deep learning is currently only available in Google's cloud services.\n",
            "\n",
            "A user might need time to build\n",
            "Score: -0.28140246868133545\n",
            "\n",
            "Response: What is deep learning?\n",
            "\n",
            "Deep learning is the process by which a processor is trained that it learns a single thing. It can then use the same training to look back at how it has learned that technique.\n",
            "\n",
            "Deep learning is similar to\n",
            "Score: 0.23582708835601807\n",
            "\n",
            "Response: What is deep learning?\n",
            "\n",
            "What is visualization?\n",
            "\n",
            "What is deep neural network?\n",
            "\n",
            "What is a self-learning algorithm\n",
            "\n",
            "What is learning\n",
            "\n",
            "What is a self-training algorithm\n",
            "\n",
            "A key example is to write\n",
            "Score: -0.5195984840393066\n",
            "\n",
            "Response: What is deep learning? And why do people prefer it to Big Data?\n",
            "\n",
            "Well, some say deep learning is just a way of making predictions about the world. Then many people try to build the algorithm on top of it to solve the problem\n",
            "Score: -0.3824896812438965\n",
            "\n",
            "Response: What is deep learning?\n",
            "\n",
            "Deep learning involves techniques to generate models for applications, known as training models. These data are then processed to create predictions about how a program will perform within those model parameters.\n",
            "\n",
            "The problem is some data was generated\n",
            "Score: 0.3027646541595459\n",
            "\n"
          ]
        }
      ]
    }
  ]
}